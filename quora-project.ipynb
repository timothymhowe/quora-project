{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Identifying Duplicate Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Over 100 million people visit Quora every month, so it's no surprise that many people ask similar (or the same) questions. Various questions with the same intent can cause people to spend extra time searching for the best answer to their question, and results in members answering multiple versions of the same question. Quora uses random forest to identify duplicated questions to provide a better experience to active seekers and writers, and offer more value to both of these groups in the long term.\n",
    "Follow the steps outlined below to build the appropriate classifier model. \n",
    "\n",
    "\n",
    "Steps:\n",
    "- Download data\n",
    "- Exploration\n",
    "- Cleaning\n",
    "- Feature Engineering\n",
    "- Modeling\n",
    "\n",
    "By the end of this project you should have **a presentation that describes the model you built** and its **performance**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Note\n",
    "There is no designated test.csv file. The train.csv file is the entire dataset. Part of the data in the train.csv file should be set aside to act as the final testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train.csv\",index_col=0)\n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "\n",
    "y = df['is_duplicate']\n",
    "X = df.drop('is_duplicate',axis=1)\n",
    "\n",
    "y.index = X.index\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, train_size=.75,random_state=1923)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "count    303215.000000\nmean         10.938948\nstd           5.434235\nmin           1.000000\n25%           7.000000\n50%          10.000000\n75%          13.000000\nmax         125.000000\nName: question1, dtype: float64"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%matplotlib inline\n",
    "\n",
    "X_train['question1'].map(lambda x: len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1440x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1,ax2) = plt.subplots(2,1,sharex='all',figsize=(20,5))\n",
    "ax1.boxplot(X_train['question1'].map(lambda x: len(x.split())), vert=False,);\n",
    "ax2.boxplot(X_train['question2'].map(lambda x: len(x.split())),vert=False);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1440x360 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, (ax1,ax2) = plt.subplots(2,1,sharex=True,figsize=(20,5));\n",
    "ax1.hist(X_train['question1'].map(lambda x: len(x.split())),bins=100, log=True);\n",
    "ax2.hist(X_train['question2'].map(lambda x: len(x.split())),bins=100, log=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "ugh = df['qid1'].to_numpy()\n",
    "lenlen = len(set(ugh.tolist() + df['qid2'].to_numpy().tolist()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                qid1           qid2   is_duplicate\ncount  404287.000000  404287.000000  404287.000000\nmean   217243.151093  220955.212082       0.369201\nstd    157751.614317  159903.168488       0.482589\nmin         1.000000       2.000000       0.000000\n25%     74436.500000   74726.500000       0.000000\n50%    192181.000000  197053.000000       0.000000\n75%    346573.000000  354692.000000       1.000000\nmax    537932.000000  537933.000000       1.000000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid1</th>\n      <th>qid2</th>\n      <th>is_duplicate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>404287.000000</td>\n      <td>404287.000000</td>\n      <td>404287.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>217243.151093</td>\n      <td>220955.212082</td>\n      <td>0.369201</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>157751.614317</td>\n      <td>159903.168488</td>\n      <td>0.482589</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>74436.500000</td>\n      <td>74726.500000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>192181.000000</td>\n      <td>197053.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>346573.000000</td>\n      <td>354692.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>537932.000000</td>\n      <td>537933.000000</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "290652\n",
      "299362\n"
     ]
    }
   ],
   "source": [
    "print(len(set(df['qid1'])))\n",
    "\n",
    "print(len(set(df['qid2'])))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404287\n"
     ]
    }
   ],
   "source": [
    "print(len(df['qid1']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Word Tokenization\n",
    "from nltk.tokenize import NLTKWordTokenizer\n",
    "\n",
    "tokenizer = NLTKWordTokenizer()\n",
    "X_train['question1_tokens'] = X_train['question1'].map(tokenizer.tokenize)\n",
    "X_train['question2_tokens'] = X_train['question2'].map(tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Remove Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "X_train2 = X_train\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "X_train2['question1_tokens'] = X_train['question1_tokens'].map(lambda xs : [x for x in xs if not x.lower() in sw])\n",
    "X_train2['question2_tokens'] = X_train['question2_tokens'].map(lambda xs : [x for x in xs if not x.lower() in sw])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# remove punctuation\n",
    "from string import punctuation as punc_list\n",
    "X_train2['question1_tokens'] = X_train2['question1_tokens'].map(lambda xs : [x for x in xs if not x in punc_list])\n",
    "X_train2['question2_tokens'] = X_train2['question2_tokens'].map(lambda xs : [x for x in xs if not x in punc_list])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Use porter's algorithm to get stems, and convert to lowercase!\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "X_train2['question1_tokens'] = X_train2['question1_tokens'].map(lambda xs : [stemmer.stem(x, to_lowercase=True) for x in xs])\n",
    "X_train2['question2_tokens'] = X_train2['question2_tokens'].map(lambda xs : [stemmer.stem(x,to_lowercase=True) for x in xs])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "          qid1                                   question1_tokens    qid2  \\\nid                                                                          \n20369    38434                             [3, main, compon, cpu]   38435   \n128211  206240    [posit, neg, implic, could, come, time, travel]  206241   \n207728  311500     [feel, see, time, 9:11, everytim, look, clock]  311501   \n327614   14244           [one, correct, lunch, lunch, ate, lunch]   34902   \n206680  310177                                      [read, quora]  120989   \n...        ...                                                ...     ...   \n363276  227992  [place, india, everi, indian, visit, least, life]  385352   \n308849   26089                                [live, happi, life]  260208   \n151699  238470                      [factori, reset, ipod, touch]  238471   \n328037  172373                     [canon, lens, get, 750d, 760d]  454544   \n254671   61668           [common, trait, highli, intellig, peopl]  369445   \n\n                                         question2_tokens  \nid                                                         \n20369                                 [main, compon, cpu]  \n128211                           [dark, upper, lip, turn]  \n207728                   [mean, alway, see, 20:20, clock]  \n327614                               [determin, use, etc]  \n206680                                [peopl, use, quora]  \n...                                                   ...  \n363276               [place, everyon, visit, india, life]  \n308849       [person, live, success, happi, life, invest]  \n151699             [perform, factori, reset, ipod, touch]  \n328037  [take, good, photo, use, canon, eo, 750d, also...  \n254671  [peopl, high, intellig, look, peopl, normal, i...  \n\n[303215 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid1</th>\n      <th>question1_tokens</th>\n      <th>qid2</th>\n      <th>question2_tokens</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20369</th>\n      <td>38434</td>\n      <td>[3, main, compon, cpu]</td>\n      <td>38435</td>\n      <td>[main, compon, cpu]</td>\n    </tr>\n    <tr>\n      <th>128211</th>\n      <td>206240</td>\n      <td>[posit, neg, implic, could, come, time, travel]</td>\n      <td>206241</td>\n      <td>[dark, upper, lip, turn]</td>\n    </tr>\n    <tr>\n      <th>207728</th>\n      <td>311500</td>\n      <td>[feel, see, time, 9:11, everytim, look, clock]</td>\n      <td>311501</td>\n      <td>[mean, alway, see, 20:20, clock]</td>\n    </tr>\n    <tr>\n      <th>327614</th>\n      <td>14244</td>\n      <td>[one, correct, lunch, lunch, ate, lunch]</td>\n      <td>34902</td>\n      <td>[determin, use, etc]</td>\n    </tr>\n    <tr>\n      <th>206680</th>\n      <td>310177</td>\n      <td>[read, quora]</td>\n      <td>120989</td>\n      <td>[peopl, use, quora]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>363276</th>\n      <td>227992</td>\n      <td>[place, india, everi, indian, visit, least, life]</td>\n      <td>385352</td>\n      <td>[place, everyon, visit, india, life]</td>\n    </tr>\n    <tr>\n      <th>308849</th>\n      <td>26089</td>\n      <td>[live, happi, life]</td>\n      <td>260208</td>\n      <td>[person, live, success, happi, life, invest]</td>\n    </tr>\n    <tr>\n      <th>151699</th>\n      <td>238470</td>\n      <td>[factori, reset, ipod, touch]</td>\n      <td>238471</td>\n      <td>[perform, factori, reset, ipod, touch]</td>\n    </tr>\n    <tr>\n      <th>328037</th>\n      <td>172373</td>\n      <td>[canon, lens, get, 750d, 760d]</td>\n      <td>454544</td>\n      <td>[take, good, photo, use, canon, eo, 750d, also...</td>\n    </tr>\n    <tr>\n      <th>254671</th>\n      <td>61668</td>\n      <td>[common, trait, highli, intellig, peopl]</td>\n      <td>369445</td>\n      <td>[peopl, high, intellig, look, peopl, normal, i...</td>\n    </tr>\n  </tbody>\n</table>\n<p>303215 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train2[['qid1','question1_tokens','qid2','question2_tokens']]\n",
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.base import BaseEstimator\n",
    "class QuoraCleaner(BaseEstimator,TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "\n",
    "    def transform(self,X,y=None):\n",
    "        # tokenize strings\n",
    "        from nltk.tokenize import NLTKWordTokenizer\n",
    "        tokenizer = NLTKWordTokenizer()\n",
    "        X['question1_tokens'] = X['question1'].map(tokenizer.tokenize)\n",
    "        X['question2_tokens'] = X['question2'].map(tokenizer.tokenize)\n",
    "\n",
    "        # remove stopwords\n",
    "        from nltk.corpus import stopwords\n",
    "        sw = stopwords.words('english')\n",
    "        X['question1_tokens'] = X['question1_tokens'].map(lambda xs : [x for x in xs if not x.lower() in sw])\n",
    "        X['question2_tokens'] = X['question2_tokens'].map(lambda xs : [x for x in xs if not x.lower() in sw])\n",
    "\n",
    "        # remove punctuation\n",
    "        from string import punctuation as punc_list\n",
    "        X['question1_tokens'] = X['question1_tokens'].map(lambda xs : [x for x in xs if not x in punc_list])\n",
    "        X['question2_tokens'] = X['question2_tokens'].map(lambda xs : [x for x in xs if not x in punc_list])\n",
    "\n",
    "        # Use porter's algorithm to get stems.\n",
    "        from nltk.stem import PorterStemmer\n",
    "        stemmer = PorterStemmer()\n",
    "        X['question1_tokens'] = X['question1_tokens'].map(lambda xs : [stemmer.stem(x, to_lowercase=True) for x in xs])\n",
    "        X['question2_tokens'] = X['question2_tokens'].map(lambda xs : [stemmer.stem(x,to_lowercase=True) for x in xs])\n",
    "\n",
    "        X = X[['qid1','question1_tokens','qid2','question2_tokens']]\n",
    "\n",
    "        return X\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- word2vec\n",
    "- word count\n",
    "- number of the same words in both questions\n",
    "- ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# get uniq list of all documents for vectorization\n",
    "import numpy as np\n",
    "\n",
    "temp1 = X_train[['qid1','question1_tokens']].groupby('qid1').first()\n",
    "temp1 = temp1.reset_index()\n",
    "\n",
    "temp1.columns = ['qid','tokens']\n",
    "\n",
    "temp2 = X_train[['qid2','question2_tokens']].groupby('qid2').first()\n",
    "temp2 = temp2.reset_index()\n",
    "temp2.columns = ['qid','tokens']\n",
    "uniqs = pd.concat([temp1,temp2],axis=0).groupby('qid').first()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec_count = CountVectorizer(preprocessor=' '.join)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tran_tfidf = TfidfTransformer()\n",
    "\n",
    "# tfidf_pipe = Pipeline([('count',vec_count),('tfidf',tran_tfidf)]).fit(uniqs['tokens'])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec_tfidf = TfidfVectorizer(preprocessor=' '.join,ngram_range=(1,3)).fit(uniqs['tokens'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "q1_tfidf = vec_tfidf.transform(X_train['question1_tokens'])\n",
    "q2_tfidf = vec_tfidf.transform(X_train['question2_tokens'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thowe\\AppData\\Local\\Temp\\ipykernel_13828\\1996137371.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train['tfidf_cos_distances'] = paired_cosine_distances(q1_tfidf,q2_tfidf)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "X_train['tfidf_cos_distances'] = paired_cosine_distances(q1_tfidf,q2_tfidf)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex, SparseTermSimilarityMatrix, SoftCosineSimilarity\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "w2v = word2vec.load_word2vec_format('C:/Users/thowe/.word2vec/GoogleNews-vectors-negative300.bin',binary=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "q1_num_words = X_train['question1_tokens'].apply(len)\n",
    "q2_num_words = X_train['question2_tokens'].apply(len)\n",
    "X_train['difference_in_number_of_words'] = q1_num_words - q2_num_words\n",
    "\n",
    "def cosine_sim(vecA, vecB):\n",
    "    \"\"\"\n",
    "    Find the cosine similarity distance between two vectors.\n",
    "\n",
    "    :param vecA: the first vector for the similarity calculation\n",
    "    :param vecB: the second vector for the similarity calculation\n",
    "    :return: The cosine similarity of the two vectors\n",
    "    \"\"\"\n",
    "    cos_sim = np.dot(vecA, vecB) / (np.linalg.norm(vecA) * np.linalg.norm(vecB))\n",
    "    if np.isnan(np.sum(cos_sim)):\n",
    "        return 0\n",
    "    return cos_sim"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "data": {
      "text/plain": "                          0\n0                      </s>\n1                        in\n2                       for\n3                      that\n4                        is\n...                     ...\n2999995             raffael\n2999996       bim_skala_bim\n2999997           mezze_caf\n2999998    pulverizes_bould\n2999999  snowcapped_caucasu\n\n[3000000 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>&lt;/s&gt;</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>in</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>for</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>that</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>is</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2999995</th>\n      <td>raffael</td>\n    </tr>\n    <tr>\n      <th>2999996</th>\n      <td>bim_skala_bim</td>\n    </tr>\n    <tr>\n      <th>2999997</th>\n      <td>mezze_caf</td>\n    </tr>\n    <tr>\n      <th>2999998</th>\n      <td>pulverizes_bould</td>\n    </tr>\n    <tr>\n      <th>2999999</th>\n      <td>snowcapped_caucasu</td>\n    </tr>\n  </tbody>\n</table>\n<p>3000000 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# keys = w2v.index_to_key\n",
    "vocab = np.concatenate(list(uniqs['tokens']))\n",
    "vocab = list(set(vocab))\n",
    "len(vocab)\n",
    "w2v_stems = pd.DataFrame(w2v.index_to_key).applymap(stemmer.stem)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "84280"
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                   tokens\nqid                                                      \n3                  [stori, kohinoor, koh-i-noor, diamond]\n4       [would, happen, indian, govern, stole, kohinoo...\n5           [increas, speed, internet, connect, use, vpn]\n6                    [internet, speed, increas, hack, dn]\n7                                    [mental, lone, solv]\n...                                                   ...\n537925      [cpu, upgrad, 2016, appl, macbook, pro, mean]\n537926                           [jainism, say, homosexu]\n537927                      [jainism, say, gay, homosexu]\n537928                                        [one, coin]\n537929                                         ['s, coin]\n\n[427020 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tokens</th>\n    </tr>\n    <tr>\n      <th>qid</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>[stori, kohinoor, koh-i-noor, diamond]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[would, happen, indian, govern, stole, kohinoo...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[increas, speed, internet, connect, use, vpn]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[internet, speed, increas, hack, dn]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[mental, lone, solv]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>537925</th>\n      <td>[cpu, upgrad, 2016, appl, macbook, pro, mean]</td>\n    </tr>\n    <tr>\n      <th>537926</th>\n      <td>[jainism, say, homosexu]</td>\n    </tr>\n    <tr>\n      <th>537927</th>\n      <td>[jainism, say, gay, homosexu]</td>\n    </tr>\n    <tr>\n      <th>537928</th>\n      <td>[one, coin]</td>\n    </tr>\n    <tr>\n      <th>537929</th>\n      <td>['s, coin]</td>\n    </tr>\n  </tbody>\n</table>\n<p>427020 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "embed_dict = {}\n",
    "\n",
    "stem_dict = []\n",
    "for index, word in enumerate(vocab):\n",
    "    try:\n",
    "        idx_dict[index] = w2v[word]\n",
    "    except:\n",
    "        pass\n",
    "del w2v"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "keys=embed_dict.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "# documents = [TaggedDocument(doc, tags=[i]) for i, doc in uniqs.iterrows()]\n",
    "documents2 = [TaggedDocument(*doc, tags=[i]) for i, doc in uniqs.iterrows()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [],
   "source": [
    "model = Doc2Vec(documents2, vector_size=50, window=5, min_count=1, workers=7,epochs=1,negative=0,hs=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Word2Vec._train_epoch() got an unexpected keyword argument 'negative'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [148]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtotal_words\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvocab\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtotal_examples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43muniqs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcorpus_iterable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocuments2\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mreport_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mnegative\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mhs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\gensim\\models\\doc2vec.py:516\u001B[0m, in \u001B[0;36mDoc2Vec.train\u001B[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m    513\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moffsets\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m offsets\n\u001B[0;32m    514\u001B[0m     kwargs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstart_doctags\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m start_doctags\n\u001B[1;32m--> 516\u001B[0m \u001B[38;5;28msuper\u001B[39m(Doc2Vec, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mtrain(\n\u001B[0;32m    517\u001B[0m     corpus_iterable\u001B[38;5;241m=\u001B[39mcorpus_iterable, corpus_file\u001B[38;5;241m=\u001B[39mcorpus_file,\n\u001B[0;32m    518\u001B[0m     total_examples\u001B[38;5;241m=\u001B[39mtotal_examples, total_words\u001B[38;5;241m=\u001B[39mtotal_words,\n\u001B[0;32m    519\u001B[0m     epochs\u001B[38;5;241m=\u001B[39mepochs, start_alpha\u001B[38;5;241m=\u001B[39mstart_alpha, end_alpha\u001B[38;5;241m=\u001B[39mend_alpha, word_count\u001B[38;5;241m=\u001B[39mword_count,\n\u001B[0;32m    520\u001B[0m     queue_factor\u001B[38;5;241m=\u001B[39mqueue_factor, report_delay\u001B[38;5;241m=\u001B[39mreport_delay, callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\gensim\\models\\word2vec.py:1070\u001B[0m, in \u001B[0;36mWord2Vec.train\u001B[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001B[0m\n\u001B[0;32m   1067\u001B[0m     callback\u001B[38;5;241m.\u001B[39mon_epoch_begin(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m   1069\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m corpus_iterable \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1070\u001B[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_epoch(\n\u001B[0;32m   1071\u001B[0m         corpus_iterable, cur_epoch\u001B[38;5;241m=\u001B[39mcur_epoch, total_examples\u001B[38;5;241m=\u001B[39mtotal_examples,\n\u001B[0;32m   1072\u001B[0m         total_words\u001B[38;5;241m=\u001B[39mtotal_words, queue_factor\u001B[38;5;241m=\u001B[39mqueue_factor, report_delay\u001B[38;5;241m=\u001B[39mreport_delay,\n\u001B[0;32m   1073\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1074\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1075\u001B[0m     trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_train_epoch_corpusfile(\n\u001B[0;32m   1076\u001B[0m         corpus_file, cur_epoch\u001B[38;5;241m=\u001B[39mcur_epoch, total_examples\u001B[38;5;241m=\u001B[39mtotal_examples, total_words\u001B[38;5;241m=\u001B[39mtotal_words,\n\u001B[0;32m   1077\u001B[0m         callbacks\u001B[38;5;241m=\u001B[39mcallbacks, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mTypeError\u001B[0m: Word2Vec._train_epoch() got an unexpected keyword argument 'negative'"
     ]
    }
   ],
   "source": [
    "model.train(total_words=len(vocab),total_examples=len(uniqs),corpus_iterable=documents2,epochs=5,report_delay=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "[0,\n 1,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n 27,\n 28,\n 29,\n 30,\n 31,\n 32,\n 33,\n 34,\n 35,\n 36,\n 37,\n 38,\n 39,\n 40,\n 41,\n 42,\n 43,\n 44,\n 45,\n 46,\n 47,\n 48,\n 49,\n 50,\n 51,\n 52,\n 53,\n 54,\n 55,\n 56,\n 57,\n 58,\n 59,\n 60,\n 61,\n 62,\n 63,\n 64,\n 65,\n 66,\n 67,\n 68,\n 69,\n 70,\n 71,\n 72,\n 73,\n 74,\n 75,\n 76,\n 77,\n 78,\n 79,\n 80,\n 81,\n 82,\n 83,\n 84,\n 85,\n 86,\n 87,\n 88,\n 89,\n 90,\n 91,\n 92,\n 93,\n 94,\n 95,\n 96,\n 97,\n 98,\n 99,\n 100,\n 101,\n 102,\n 103,\n 104,\n 105,\n 106,\n 107,\n 108,\n 109,\n 110,\n 111,\n 112,\n 113,\n 114,\n 115,\n 116,\n 117,\n 118,\n 119,\n 120,\n 121,\n 122,\n 123,\n 124,\n 125,\n 126,\n 127,\n 128,\n 129,\n 130,\n 131,\n 132,\n 133,\n 134,\n 135,\n 136,\n 137,\n 138,\n 139,\n 140,\n 141,\n 142,\n 143,\n 144,\n 145,\n 146,\n 147,\n 148,\n 149,\n 150,\n 151,\n 152,\n 153,\n 154,\n 155,\n 156,\n 157,\n 158,\n 159,\n 160,\n 161,\n 162,\n 163,\n 164,\n 165,\n 166,\n 167,\n 168,\n 169,\n 170,\n 171,\n 172,\n 173,\n 174,\n 175,\n 176,\n 177,\n 178,\n 179,\n 180,\n 181,\n 182,\n 183,\n 184,\n 185,\n 186,\n 187,\n 188,\n 189,\n 190,\n 191,\n 192,\n 193,\n 194,\n 195,\n 196,\n 197,\n 198,\n 199,\n 200,\n 201,\n 202,\n 203,\n 204,\n 205,\n 206,\n 207,\n 208,\n 209,\n 210,\n 211,\n 212,\n 213,\n 214,\n 215,\n 216,\n 217,\n 218,\n 219,\n 220,\n 221,\n 222,\n 223,\n 224,\n 225,\n 226,\n 227,\n 228,\n 229,\n 230,\n 231,\n 232,\n 233,\n 234,\n 235,\n 236,\n 237,\n 238,\n 239,\n 240,\n 241,\n 242,\n 243,\n 244,\n 245,\n 246,\n 247,\n 248,\n 249,\n 250,\n 251,\n 252,\n 253,\n 254,\n 255,\n 256,\n 257,\n 258,\n 259,\n 260,\n 261,\n 262,\n 263,\n 264,\n 265,\n 266,\n 267,\n 268,\n 269,\n 270,\n 271,\n 272,\n 273,\n 274,\n 275,\n 276,\n 277,\n 278,\n 279,\n 280,\n 281,\n 282,\n 283,\n 284,\n 285,\n 286,\n 287,\n 288,\n 289,\n 290,\n 291,\n 292,\n 293,\n 294,\n 295,\n 296,\n 297,\n 298,\n 299,\n 300,\n 301,\n 302,\n 303,\n 304,\n 305,\n 306,\n 307,\n 308,\n 309,\n 310,\n 311,\n 312,\n 313,\n 314,\n 315,\n 316,\n 317,\n 318,\n 319,\n 320,\n 321,\n 322,\n 323,\n 324,\n 325,\n 326,\n 327,\n 328,\n 329,\n 330,\n 331,\n 332,\n 333,\n 334,\n 335,\n 336,\n 337,\n 338,\n 339,\n 340,\n 341,\n 342,\n 343,\n 344,\n 345,\n 346,\n 347,\n 348,\n 349,\n 350,\n 351,\n 352,\n 353,\n 354,\n 355,\n 356,\n 357,\n 358,\n 359,\n 360,\n 361,\n 362,\n 363,\n 364,\n 365,\n 366,\n 367,\n 368,\n 369,\n 370,\n 371,\n 372,\n 373,\n 374,\n 375,\n 376,\n 377,\n 378,\n 379,\n 380,\n 381,\n 382,\n 383,\n 384,\n 385,\n 386,\n 387,\n 388,\n 389,\n 390,\n 391,\n 392,\n 393,\n 394,\n 395,\n 396,\n 397,\n 398,\n 399,\n 400,\n 401,\n 402,\n 403,\n 404,\n 405,\n 406,\n 407,\n 408,\n 409,\n 410,\n 411,\n 412,\n 413,\n 414,\n 415,\n 416,\n 417,\n 418,\n 419,\n 420,\n 421,\n 422,\n 423,\n 424,\n 425,\n 426,\n 427,\n 428,\n 429,\n 430,\n 431,\n 432,\n 433,\n 434,\n 435,\n 436,\n 437,\n 438,\n 439,\n 440,\n 441,\n 442,\n 443,\n 444,\n 445,\n 446,\n 447,\n 448,\n 449,\n 450,\n 451,\n 452,\n 453,\n 454,\n 455,\n 456,\n 457,\n 458,\n 459,\n 460,\n 461,\n 462,\n 463,\n 464,\n 465,\n 466,\n 467,\n 468,\n 469,\n 470,\n 471,\n 472,\n 473,\n 474,\n 475,\n 476,\n 477,\n 478,\n 479,\n 480,\n 481,\n 482,\n 483,\n 484,\n 485,\n 486,\n 487,\n 488,\n 489,\n 490,\n 491,\n 492,\n 493,\n 494,\n 495,\n 496,\n 497,\n 498,\n 499,\n 500,\n 501,\n 502,\n 503,\n 504,\n 505,\n 506,\n 507,\n 508,\n 509,\n 510,\n 511,\n 512,\n 513,\n 514,\n 515,\n 516,\n 517,\n 518,\n 519,\n 520,\n 521,\n 522,\n 523,\n 524,\n 525,\n 526,\n 527,\n 528,\n 529,\n 530,\n 531,\n 532,\n 533,\n 534,\n 535,\n 536,\n 537,\n 538,\n 539,\n 540,\n 541,\n 542,\n 543,\n 544,\n 545,\n 546,\n 547,\n 548,\n 549,\n 550,\n 551,\n 552,\n 553,\n 554,\n 555,\n 556,\n 557,\n 558,\n 559,\n 560,\n 561,\n 562,\n 563,\n 564,\n 565,\n 566,\n 567,\n 568,\n 569,\n 570,\n 571,\n 572,\n 573,\n 574,\n 575,\n 576,\n 577,\n 578,\n 579,\n 580,\n 581,\n 582,\n 583,\n 584,\n 585,\n 586,\n 587,\n 588,\n 589,\n 590,\n 591,\n 592,\n 593,\n 594,\n 595,\n 596,\n 597,\n 598,\n 599,\n 600,\n 601,\n 602,\n 603,\n 604,\n 605,\n 606,\n 607,\n 608,\n 609,\n 610,\n 611,\n 612,\n 613,\n 614,\n 615,\n 616,\n 617,\n 618,\n 619,\n 620,\n 621,\n 622,\n 623,\n 624,\n 625,\n 626,\n 627,\n 628,\n 629,\n 630,\n 631,\n 632,\n 633,\n 634,\n 635,\n 636,\n 637,\n 638,\n 639,\n 640,\n 641,\n 642,\n 643,\n 644,\n 645,\n 646,\n 647,\n 648,\n 649,\n 650,\n 651,\n 652,\n 653,\n 654,\n 655,\n 656,\n 657,\n 658,\n 659,\n 660,\n 661,\n 662,\n 663,\n 664,\n 665,\n 666,\n 667,\n 668,\n 669,\n 670,\n 671,\n 672,\n 673,\n 674,\n 675,\n 676,\n 677,\n 678,\n 679,\n 680,\n 681,\n 682,\n 683,\n 684,\n 685,\n 686,\n 687,\n 688,\n 689,\n 690,\n 691,\n 692,\n 693,\n 694,\n 695,\n 696,\n 697,\n 698,\n 699,\n 700,\n 701,\n 702,\n 703,\n 704,\n 705,\n 706,\n 707,\n 708,\n 709,\n 710,\n 711,\n 712,\n 713,\n 714,\n 715,\n 716,\n 717,\n 718,\n 719,\n 720,\n 721,\n 722,\n 723,\n 724,\n 725,\n 726,\n 727,\n 728,\n 729,\n 730,\n 731,\n 732,\n 733,\n 734,\n 735,\n 736,\n 737,\n 738,\n 739,\n 740,\n 741,\n 742,\n 743,\n 744,\n 745,\n 746,\n 747,\n 748,\n 749,\n 750,\n 751,\n 752,\n 753,\n 754,\n 755,\n 756,\n 757,\n 758,\n 759,\n 760,\n 761,\n 762,\n 763,\n 764,\n 765,\n 766,\n 767,\n 768,\n 769,\n 770,\n 771,\n 772,\n 773,\n 774,\n 775,\n 776,\n 777,\n 778,\n 779,\n 780,\n 781,\n 782,\n 783,\n 784,\n 785,\n 786,\n 787,\n 788,\n 789,\n 790,\n 791,\n 792,\n 793,\n 794,\n 795,\n 796,\n 797,\n 798,\n 799,\n 800,\n 801,\n 802,\n 803,\n 804,\n 805,\n 806,\n 807,\n 808,\n 809,\n 810,\n 811,\n 812,\n 813,\n 814,\n 815,\n 816,\n 817,\n 818,\n 819,\n 820,\n 821,\n 822,\n 823,\n 824,\n 825,\n 826,\n 827,\n 828,\n 829,\n 830,\n 831,\n 832,\n 833,\n 834,\n 835,\n 836,\n 837,\n 838,\n 839,\n 840,\n 841,\n 842,\n 843,\n 844,\n 845,\n 846,\n 847,\n 848,\n 849,\n 850,\n 851,\n 852,\n 853,\n 854,\n 855,\n 856,\n 857,\n 858,\n 859,\n 860,\n 861,\n 862,\n 863,\n 864,\n 865,\n 866,\n 867,\n 868,\n 869,\n 870,\n 871,\n 872,\n 873,\n 874,\n 875,\n 876,\n 877,\n 878,\n 879,\n 880,\n 881,\n 882,\n 883,\n 884,\n 885,\n 886,\n 887,\n 888,\n 889,\n 890,\n 891,\n 892,\n 893,\n 894,\n 895,\n 896,\n 897,\n 898,\n 899,\n 900,\n 901,\n 902,\n 903,\n 904,\n 905,\n 906,\n 907,\n 908,\n 909,\n 910,\n 911,\n 912,\n 913,\n 914,\n 915,\n 916,\n 917,\n 918,\n 919,\n 920,\n 921,\n 922,\n 923,\n 924,\n 925,\n 926,\n 927,\n 928,\n 929,\n 930,\n 931,\n 932,\n 933,\n 934,\n 935,\n 936,\n 937,\n 938,\n 939,\n 940,\n 941,\n 942,\n 943,\n 944,\n 945,\n 946,\n 947,\n 948,\n 949,\n 950,\n 951,\n 952,\n 953,\n 954,\n 955,\n 956,\n 957,\n 958,\n 959,\n 960,\n 961,\n 962,\n 963,\n 964,\n 965,\n 966,\n 967,\n 968,\n 969,\n 970,\n 971,\n 972,\n 973,\n 974,\n 975,\n 976,\n 977,\n 978,\n 979,\n 980,\n 981,\n 982,\n 983,\n 984,\n 985,\n 986,\n 987,\n 988,\n 989,\n 990,\n 991,\n 992,\n 993,\n 994,\n 995,\n 996,\n 997,\n 998,\n 999,\n ...]"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.dv.index_to_key"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "outputs": [
    {
     "data": {
      "text/plain": "          qid1                                   question1_tokens    qid2  \\\nid                                                                          \n20369    38434                             [3, main, compon, cpu]   38435   \n128211  206240    [posit, neg, implic, could, come, time, travel]  206241   \n207728  311500     [feel, see, time, 9:11, everytim, look, clock]  311501   \n327614   14244           [one, correct, lunch, lunch, ate, lunch]   34902   \n206680  310177                                      [read, quora]  120989   \n...        ...                                                ...     ...   \n363276  227992  [place, india, everi, indian, visit, least, life]  385352   \n308849   26089                                [live, happi, life]  260208   \n151699  238470                      [factori, reset, ipod, touch]  238471   \n328037  172373                     [canon, lens, get, 750d, 760d]  454544   \n254671   61668           [common, trait, highli, intellig, peopl]  369445   \n\n                                         question2_tokens  \\\nid                                                          \n20369                                 [main, compon, cpu]   \n128211                           [dark, upper, lip, turn]   \n207728                   [mean, alway, see, 20:20, clock]   \n327614                               [determin, use, etc]   \n206680                                [peopl, use, quora]   \n...                                                   ...   \n363276               [place, everyon, visit, india, life]   \n308849       [person, live, success, happi, life, invest]   \n151699             [perform, factori, reset, ipod, touch]   \n328037  [take, good, photo, use, canon, eo, 750d, also...   \n254671  [peopl, high, intellig, look, peopl, normal, i...   \n\n        tfidf_cos_distances  difference_in_number_of_words  \\\nid                                                           \n20369              0.000000                              1   \n128211             1.000000                              3   \n207728             0.942349                              2   \n327614             1.000000                              3   \n206680             0.885291                             -1   \n...                     ...                            ...   \n363276             0.919887                              2   \n308849             0.760763                             -3   \n151699             0.151386                             -1   \n328037             0.870352                            -12   \n254671             0.911146                             -2   \n\n        mean_w2v_cos_similarity  difference_in_word_vec_sum  \nid                                                           \n20369                         0                         0.0  \n128211                        0                         0.0  \n207728                        0                         0.0  \n327614                        0                         0.0  \n206680                        0                         0.0  \n...                         ...                         ...  \n363276                        0                         0.0  \n308849                        0                         0.0  \n151699                        0                         0.0  \n328037                        0                         0.0  \n254671                        0                         0.0  \n\n[303215 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid1</th>\n      <th>question1_tokens</th>\n      <th>qid2</th>\n      <th>question2_tokens</th>\n      <th>tfidf_cos_distances</th>\n      <th>difference_in_number_of_words</th>\n      <th>mean_w2v_cos_similarity</th>\n      <th>difference_in_word_vec_sum</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20369</th>\n      <td>38434</td>\n      <td>[3, main, compon, cpu]</td>\n      <td>38435</td>\n      <td>[main, compon, cpu]</td>\n      <td>0.000000</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>128211</th>\n      <td>206240</td>\n      <td>[posit, neg, implic, could, come, time, travel]</td>\n      <td>206241</td>\n      <td>[dark, upper, lip, turn]</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>207728</th>\n      <td>311500</td>\n      <td>[feel, see, time, 9:11, everytim, look, clock]</td>\n      <td>311501</td>\n      <td>[mean, alway, see, 20:20, clock]</td>\n      <td>0.942349</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>327614</th>\n      <td>14244</td>\n      <td>[one, correct, lunch, lunch, ate, lunch]</td>\n      <td>34902</td>\n      <td>[determin, use, etc]</td>\n      <td>1.000000</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>206680</th>\n      <td>310177</td>\n      <td>[read, quora]</td>\n      <td>120989</td>\n      <td>[peopl, use, quora]</td>\n      <td>0.885291</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>363276</th>\n      <td>227992</td>\n      <td>[place, india, everi, indian, visit, least, life]</td>\n      <td>385352</td>\n      <td>[place, everyon, visit, india, life]</td>\n      <td>0.919887</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>308849</th>\n      <td>26089</td>\n      <td>[live, happi, life]</td>\n      <td>260208</td>\n      <td>[person, live, success, happi, life, invest]</td>\n      <td>0.760763</td>\n      <td>-3</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>151699</th>\n      <td>238470</td>\n      <td>[factori, reset, ipod, touch]</td>\n      <td>238471</td>\n      <td>[perform, factori, reset, ipod, touch]</td>\n      <td>0.151386</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>328037</th>\n      <td>172373</td>\n      <td>[canon, lens, get, 750d, 760d]</td>\n      <td>454544</td>\n      <td>[take, good, photo, use, canon, eo, 750d, also...</td>\n      <td>0.870352</td>\n      <td>-12</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>254671</th>\n      <td>61668</td>\n      <td>[common, trait, highli, intellig, peopl]</td>\n      <td>369445</td>\n      <td>[peopl, high, intellig, look, peopl, normal, i...</td>\n      <td>0.911146</td>\n      <td>-2</td>\n      <td>0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303215 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thowe\\miniconda3\\envs\\LighthouseEnv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q1_word_vec_mean = X_train['question1_tokens'].apply(lambda xs: np.mean([model.wv[x] for x in xs ],axis=0))\n",
    "q2_word_vec_mean = X_train['question2_tokens'].apply(lambda xs: np.mean([model.wv[x] for x in xs ],axis=0))\n",
    "# q1_word_vec_mean = X_train['question1_tokens'].apply(lambda xs: np.mean([model.wv[x] for x in xs if x in keys],axis=0))\n",
    "# q2_word_vec_mean = X_train['question2_tokens'].apply(lambda xs: np.mean([model.wv[x] for x in xs if x in keys],axis=0))\n",
    "X_train['mean_w2v_cos_similarity'] = [cosine_sim(a,b) for a, b in zip(q1_word_vec_mean,q2_word_vec_mean)]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "outputs": [],
   "source": [
    "# q1_word_vec_sum = X_train['question1_tokens'].apply(lambda xs: np.sum([embed_dict[x] for x in xs if x in keys],axis=0))\n",
    "# q2_word_vec_sum = X_train['question2_tokens'].apply(lambda xs: np.sum([embed_dict[x] for x in xs if x in keys],axis=0))\n",
    "\n",
    "q1_word_vec_sum = X_train['question1_tokens'].apply(lambda xs: np.sum([model.wv[x] for x in xs],axis=0))\n",
    "q2_word_vec_sum = X_train['question2_tokens'].apply(lambda xs: np.sum([model.wv[x] for x in xs],axis=0))\n",
    "X_train['difference_in_word_vec_sum'] = q1_word_vec_sum - q2_word_vec_sum"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [144]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mdv\u001B[38;5;241m.\u001B[39munit_normalize_all()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkey_to_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'dict' object is not callable"
     ]
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "outputs": [
    {
     "data": {
      "text/plain": "id\n20369                                [3, main, compon, cpu]\n128211      [posit, neg, implic, could, come, time, travel]\n207728       [feel, see, time, 9:11, everytim, look, clock]\n327614             [one, correct, lunch, lunch, ate, lunch]\n206680                                        [read, quora]\n                                ...                        \n363276    [place, india, everi, indian, visit, least, life]\n308849                                  [live, happi, life]\n151699                        [factori, reset, ipod, touch]\n328037                       [canon, lens, get, 750d, 760d]\n254671             [common, trait, highli, intellig, peopl]\nName: question1_tokens, Length: 303215, dtype: object"
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['question1_tokens']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train.difference_in_word_vec_sum.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train_f = X_train.drop(['qid1','qid2','question1_tokens','question2_tokens'],axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- LSTMs\n",
    "- etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf = XGBClassifier(random_state=1738,subsample=0.7,colsample_bytree=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train_f,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "lighthouseenv",
   "language": "python",
   "display_name": "LighthouseEnv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}